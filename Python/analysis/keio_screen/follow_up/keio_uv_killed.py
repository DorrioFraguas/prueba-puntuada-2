#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Analyse Keio Dead Bacteria experiment results- Follow-up analysis of Keio hit strains that have been UV-irradiated to kill the bacteria and test  whether the bacteria still modify worm behaviour when dead - Does the effect require a biotic interaction between the bacteria and the worm?   Is the behaviour-modifying molecule only released by the bacteria in response to being ingested?4 hours on food - standard syngenta bluelight videosPlease run the following scripts beforehand:1. preprocessing/compile_keio_results.py2. statistical_testing/perform_dead_keio_stats.pyMain feature we are using as an indicator for the rescue: 'speed_50th_bluelight'@author: sm5911@date: 19/11/2021"""#%% IMPORTSimport numpy as npimport pandas as pdimport seaborn as snsfrom tqdm import tqdmfrom pathlib import Pathfrom matplotlib import pyplot as pltfrom preprocessing.compile_hydra_data import compile_metadata, process_feature_summariesfrom filter_data.clean_feature_summaries import clean_summary_resultsfrom time_series.plot_timeseries import plot_timeseries_feature, plot_timeseriesfrom time_series.time_series_helper import get_strain_timeseriesfrom visualisation.plotting_helper import sig_asterix, all_in_one_boxplotsfrom write_data.write import write_list_to_filefrom tierpsytools.analysis.statistical_tests import univariate_tests, get_effect_sizesfrom tierpsytools.preprocessing.filter_data import select_feat_setfrom tierpsytools.analysis.statistical_tests import _multitest_correct#%% GLOBALSPROJECT_DIR = "/Volumes/hermes$/Saul/Keio_Screen/Data/Keio_UV_Killed"SAVE_DIR = "/Users/sm5911/Documents/Keio_UV_Killed"CONTROL_STRAIN = 'BW'CONTROL_TREATMENT = 'live'STRAIN_SUBSET = ['wild_type','fepD']FEATURE_SET = ['speed_50th']nan_threshold_row = 0.8nan_threshold_col = 0.2METHOD = 'complete' # 'complete','linkage','average','weighted','centroid'METRIC = 'euclidean' # 'euclidean','cosine','correlation'N_WELLS = 96FPS = 25WINDOW_DICT = {0:(65,75),1:(90,100),               2:(165,175),3:(190,200),               4:(265,275),5:(290,300)}WINDOW_NAME_DICT = {0:"blue light 1", 1: "20-30 seconds after blue light 1",                    2:"blue light 2", 3: "20-30 seconds after blue light 2",                    4:"blue light 3", 5: "20-30 seconds after blue light 3"}#%% FUNCTIONSdef uv_killing_stats(metadata,                     features,                     group_by='treatment',                     control='BW-live',                     save_dir=None,                     feature_set=None,                     pvalue_threshold=0.05,                     fdr_method='fdr_bh'):        # check case-sensitivity    assert len(metadata[group_by].unique()) == len(metadata[group_by].str.upper().unique())        if feature_set is not None:        feature_set = [feature_set] if isinstance(feature_set, str) else feature_set        assert isinstance(feature_set, list)        assert(all(f in features.columns for f in feature_set))    else:        feature_set = features.columns.tolist()            features = features[feature_set].reindex(metadata.index)    # print mean sample size    sample_size = metadata.groupby(group_by).count()    print("Mean sample size of %s: %d" % (group_by, int(sample_size[sample_size.columns[-1]].mean())))    n = len(metadata[group_by].unique())            fset = []    if n > 2:           # Perform ANOVA - is there variation among strains at each window?        anova_path = Path(save_dir) / 'ANOVA' / 'ANOVA_results.csv'        anova_path.parent.mkdir(parents=True, exist_ok=True)        stats, pvals, reject = univariate_tests(X=features,                                                 y=metadata[group_by],                                                 control=control,                                                 test='ANOVA',                                                comparison_type='multiclass',                                                multitest_correction=fdr_method,                                                alpha=pvalue_threshold,                                                n_permutation_test=None)        # get effect sizes        effect_sizes = get_effect_sizes(X=features,                                        y=metadata[group_by],                                        control=control,                                        effect_type=None,                                        linked_test='ANOVA')        # compile + save results        test_results = pd.concat([stats, effect_sizes, pvals, reject], axis=1)        test_results.columns = ['stats','effect_size','pvals','reject']             test_results['significance'] = sig_asterix(test_results['pvals'])        test_results = test_results.sort_values(by=['pvals'], ascending=True) # rank by p-value        test_results.to_csv(anova_path, header=True, index=True)        # use reject mask to find significant feature set        fset = pvals.loc[reject['ANOVA']].sort_values(by='ANOVA', ascending=True).index.to_list()        if len(fset) > 0:            print("%d significant features found by ANOVA by '%s' (P<%.2f, %s)" %\                  (len(fset), group_by, pvalue_threshold, fdr_method))            anova_sigfeats_path = anova_path.parent / 'ANOVA_sigfeats.txt'            write_list_to_file(fset, anova_sigfeats_path)                 # Perform t-tests    stats_t, pvals_t, reject_t = univariate_tests(X=features,                                                  y=metadata[group_by],                                                  control=control,                                                  test='t-test',                                                  comparison_type='binary_each_group',                                                  multitest_correction=fdr_method,                                                  alpha=pvalue_threshold)        effect_sizes_t = get_effect_sizes(X=features,                                      y=metadata[group_by],                                      control=control,                                      linked_test='t-test')        stats_t.columns = ['stats_' + str(c) for c in stats_t.columns]    pvals_t.columns = ['pvals_' + str(c) for c in pvals_t.columns]    reject_t.columns = ['reject_' + str(c) for c in reject_t.columns]    effect_sizes_t.columns = ['effect_size_' + str(c) for c in effect_sizes_t.columns]    ttest_results = pd.concat([stats_t, pvals_t, reject_t, effect_sizes_t], axis=1)        # save results    ttest_path = Path(save_dir) / 't-test' / 't-test_results.csv'    ttest_path.parent.mkdir(exist_ok=True, parents=True)    ttest_results.to_csv(ttest_path, header=True, index=True)        nsig = sum(reject_t.sum(axis=1) > 0)    print("%d significant features between any %s vs %s (t-test, P<%.2f, %s)" %\          (nsig, group_by, control, pvalue_threshold, fdr_method))    returndef main():        aux_dir = Path(PROJECT_DIR) / 'AuxiliaryFiles'    res_dir = Path(PROJECT_DIR) / 'Results'        metadata_path_local = Path(SAVE_DIR) / 'metadata.csv'    features_path_local = Path(SAVE_DIR) / 'features.csv'        if not metadata_path_local.exists() or not features_path_local.exists():        metadata, metadata_path = compile_metadata(aux_dir,                                                    n_wells=N_WELLS,                                                   imaging_dates=None,                                                   add_well_annotations=True,                                                   from_source_plate=True)                features, metadata = process_feature_summaries(metadata_path,                                                        results_dir=res_dir,                                                        compile_day_summaries=True,                                                        imaging_dates=None,                                                        align_bluelight=False,                                                        window_summaries=True,                                                       n_wells=N_WELLS)        # Clean results - Remove bad well data + features with too many NaNs/zero std + impute NaNs        features, metadata = clean_summary_results(features,                                                    metadata,                                                   feature_columns=None,                                                   nan_threshold_row=nan_threshold_row,                                                   nan_threshold_col=nan_threshold_col,                                                   max_value_cap=1e15,                                                   imputeNaN=True,                                                   min_nskel_per_video=None,                                                   min_nskel_sum=None,                                                   drop_size_related_feats=False,                                                   norm_feats_only=False)                # save clean metadata and features        metadata.to_csv(metadata_path_local, index=False)        features.to_csv(features_path_local, index=False)            else:        metadata = pd.read_csv(metadata_path_local, header=0, index_col=None, dtype={'comments':str})        features = pd.read_csv(features_path_local, header=0, index_col=None)    assert not features.isna().sum(axis=1).any()    assert not (features.std(axis=1) == 0).any()        # load feature set    if FEATURE_SET is not None:        # subset for selected feature set (and remove path curvature features)        if isinstance(FEATURE_SET, int) and FEATURE_SET in [8,16,256]:            features = select_feat_set(features, 'tierpsy_{}'.format(FEATURE_SET), append_bluelight=True)            features = features[[f for f in features.columns if 'path_curvature' not in f]]        elif isinstance(FEATURE_SET, list) or isinstance(FEATURE_SET, set):            assert all(f in features.columns for f in FEATURE_SET)            features = features[FEATURE_SET].copy()    feature_list = features.columns.tolist()    # subset metadata results for bluelight videos only     bluelight_videos = [i for i in metadata['imgstore_name'] if 'bluelight' in i]    metadata = metadata[metadata['imgstore_name'].isin(bluelight_videos)]        # add combined treatment column    metadata['is_dead'] = ['dead' if i else 'live' for i in metadata['dead']]    metadata['treatment'] = metadata[['gene_name','is_dead']].agg('-'.join, axis=1)    control = CONTROL_STRAIN + '-' + CONTROL_TREATMENT    metadata['window'] = metadata['window'].astype(int)    window_list = list(metadata['window'].unique())        strains2exclude = [s for s in metadata['gene_name'].unique() if s.startswith('trp') or s.startswith('ent')]    metadata = metadata[~metadata['gene_name'].isin(strains2exclude)]    strain_list = sorted(metadata['gene_name'].unique())    for window in tqdm(window_list):        meta_window = metadata[metadata['window']==window]        feat_window = features.reindex(meta_window.index)        stats_dir = Path(SAVE_DIR) / 'Stats' / WINDOW_NAME_DICT[window]        plot_dir = Path(SAVE_DIR) / 'Plots' / WINDOW_NAME_DICT[window]        uv_killing_stats(meta_window,                         feat_window,                         group_by='treatment',                         control=control,                         save_dir=stats_dir,                         feature_set=FEATURE_SET,                         pvalue_threshold=0.05,                         fdr_method='fdr_bh')                    all_in_one_boxplots(meta_window,                            feat_window,                            group_by='gene_name',                            hue='is_dead',                            control='BW',                            control_hue='live',                            order=None,                            hue_order=['live','dead'],                            colour_dict=None,                            save_dir=plot_dir / 'all-in-one',                            ttest_path=stats_dir / 't-test' / 't-test_results.csv',                            feature_set=feature_list,                            pvalue_threshold=0.05,                            sigasterix=True,                            fontsize=35,                            figsize=(20,15),                            ylim_minmax=(-200,350),                            vline_boxpos=None,                            legend=False,                            subplots_adjust={'bottom':0.1,'top':0.95,'left':0.1,'right':0.95})            # correct p-values for multiple comparisons: live vs dead for each strain    pvalues_dict = {}    for strain in strain_list:        meta_strain = meta_window[meta_window['gene_name']==strain]        feat_strain = feat_window.reindex(meta_strain.index)                uv_killing_stats(meta_strain,                         feat_strain,                         group_by='is_dead',                         control='live',                         save_dir=stats_dir / 'live_vs_dead_for_each_strain' / strain,                         feature_set=FEATURE_SET,                         pvalue_threshold=0.05,                         fdr_method='fdr_bh')                # read p-values for each strain and correct for multiple comparisons (fdr_bh)        pvals_df = pd.read_csv(stats_dir / 'live_vs_dead_for_each_strain' / strain / 't-test' / 't-test_results.csv',                               index_col=0)        pvalues_dict[strain] = pvals_df.loc['speed_50th','pvals_dead']        reject, corrected_pvals = _multitest_correct(pd.Series(list(pvalues_dict.values())),                                                  multitest_method='fdr_bh', fdr=0.05)    pvalues_dict = dict(zip(strain_list, corrected_pvals))    pvals = pd.DataFrame.from_dict(pvalues_dict, orient='index', columns=['pvals'])    save_path = stats_dir / 'live_vs_dead_for_each_strain' / 't-test_corrected' / 't-test_results.csv'    save_path.parent.mkdir(exist_ok=True, parents=True)    pvals.to_csv(save_path)            metadata = metadata[metadata['window']==0]    ### Timeseries     # timeseries plots of speed for each treatment vs control    keys = ['BW','fepD']    strain_list = sorted([s for s in list(metadata['treatment'].unique()) if s.split('-')[0] in keys])    plot_timeseries_feature(metadata,                            project_dir=Path(PROJECT_DIR),                            save_dir=Path(SAVE_DIR) / 'timeseries-speed',                            group_by='treatment',                            control=control,                            groups_list=strain_list,                            feature='speed',                            n_wells=96,                            bluelight_stim_type='bluelight',                            video_length_seconds=360,                            bluelight_timepoints_seconds=[(60, 70),(160, 170),(260, 270)],                            smoothing=10,                            fps=FPS,                            #ylim_minmax=(-20,330)                            )    # bespoke timeseries        rescue_list = ['fepD','fes','fepB','nuoC','sdhD','atpB']    for strain in tqdm(rescue_list):        groups = ['BW-live', strain + '-live', strain + '-dead']        print("Plotting timeseries speed for %s" % strain)                bluelight_frames = [(i*FPS, j*FPS) for (i, j) in [(60, 70),(160, 170),(260, 270)]]        feature = 'speed'        save_dir = Path(SAVE_DIR) / 'timeseries-speed' / 'rescues'        ts_plot_dir = save_dir / 'Plots' / strain        ts_plot_dir.mkdir(exist_ok=True, parents=True)        save_path = ts_plot_dir / 'speed_bluelight.pdf'                plt.close('all')        fig, ax = plt.subplots(figsize=(15,6), dpi=300)        col_dict = dict(zip(groups, sns.color_palette('tab10', len(groups))))        for group in groups:                        # get control timeseries            group_ts = get_strain_timeseries(metadata,                                             project_dir=Path(PROJECT_DIR),                                             strain=group,                                             group_by='treatment',                                             feature_list=[feature],                                             save_dir=save_dir,                                             n_wells=N_WELLS,                                             verbose=True)                        ax = plot_timeseries(df=group_ts,                                 feature=feature,                                 error=True,                                 max_n_frames=360*FPS,                                  smoothing=10*FPS,                                  ax=ax,                                 bluelight_frames=bluelight_frames,                                 colour=col_dict[group])        plt.ylim(-20, 300)        xticks = np.linspace(0, 360*FPS, int(360/60)+1)        ax.set_xticks(xticks)        ax.set_xticklabels([str(int(x/FPS/60)) for x in xticks])           ax.set_xlabel('Time (minutes)', fontsize=20, labelpad=10)        ylab = feature.replace('_50th'," (µm s$^{-1}$)")        ax.set_ylabel(ylab, fontsize=20, labelpad=10)        ax.legend(groups, fontsize=12, frameon=False, loc='best', handletextpad=1)        plt.subplots_adjust(left=0.1, top=0.98, bottom=0.15, right=0.98)        # save plot        print("Saving to: %s" % save_path)        plt.savefig(save_path)    return#%% MAINif __name__ == "__main__":    main()            